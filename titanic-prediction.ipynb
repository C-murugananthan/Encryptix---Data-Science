#loading the dataset
import pandas as pd
data = pd.read_csv('/content/Titanic-Dataset.csv')
print(data)

#data exploration
print(data.head())
print(data.describe())
print(data.info())
print(data.columns)

#data preprocessing
columns_to_drop = ['Cabin', 'Name', 'Ticket']
for col in columns_to_drop:
    if col in data.columns:
        data = data.drop(col, axis=1)
if 'Age' in data.columns:
    data['Age'].fillna(data['Age'].mean(), inplace=True)
if 'Embarked' in data.columns:
    data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)
if 'Sex' in data.columns:
    data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})
if 'Embarked' in data.columns:
    data = pd.get_dummies(data, columns=['Embarked'], drop_first=True)
print(data.head())
print(data.info())

#splitting the data
from sklearn.model_selection import train_test_split
X = data.drop('Survived',axis=1)
y = data['Survived']
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)# Verify shapes of X_train and y_train
print("Shape of X_train:", X_train.shape)
print("Shape of y_train:", y_train.shape)

# Verify data types
print("Data types of X_train:\n", X_train.dtypes)
print("Data type of y_train:", y_train.dtype)

# Check for missing values
print("Missing values in X_train:", X_train.isnull().sum().sum())
print("Missing values in y_train:", y_train.isnull().sum().sum())

# Handle missing values if present
if X_train.isnull().sum().sum() > 0:
    X_train = X_train.fillna(X_train.mean())
if y_train.isnull().sum().sum() > 0:
    y_train = y_train.fillna(y_train.mean())

# Ensure target variable is numeric
y_train = y_train.astype(int)

from sklearn.ensemble import RandomForestClassifier
# Build the model
model = RandomForestClassifier(n_estimators=100, random_state=42)
# Fit the model
try:
    model.fit(X_train, y_train)
    print("Model training successful!")
except ValueError as e:
    print(f"Error during model fitting: {e}")

from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier

# Check for missing values in X_train
print("Missing values in X_train before imputation:", X_train.isnull().sum().sum())
imputer = SimpleImputer(strategy='mean')  # You can use 'median' or 'most_frequent' depending on your data
# Fit and transform the training data
X_train_imputed = imputer.fit_transform(X_train)
# Check for missing values after imputation
print("Missing values in X_train after imputation:", pd.DataFrame(X_train_imputed).isnull().sum().sum())
# Build the model
model = RandomForestClassifier(n_estimators=100, random_state=42)

# Fit the model
try:
    model.fit(X_train_imputed, y_train)
    print("Model training successful!")
except ValueError as e:
    print(f"Error during model fitting: {e}")

from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# Load an example dataset (replace with your actual data loading)
iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)

# Initialize and train a RandomForestClassifier
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Predict using the trained model
try:
    y_pred = model.predict(X_test)
    print("Prediction successful!")
except Exception as e:
    print(f"Error during prediction: {e}")


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

# Load the Titanic dataset (replace with your actual path)
data = pd.read_csv('/content/Titanic-Dataset.csv')

# Drop columns that won't be used in training
data = data.drop(['Cabin', 'Name', 'Ticket'], axis=1)

# Fill missing values in 'Age' and 'Embarked'
imputer = SimpleImputer(strategy='mean')
data['Age'] = imputer.fit_transform(data[['Age']])
data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)

# Convert categorical 'Sex' and 'Embarked' columns to numerical
data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})
data = pd.get_dummies(data, columns=['Embarked'], drop_first=True)

# Split data into features (X) and target (y)
X = data.drop('Survived', axis=1)
y = data['Survived']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the RandomForestClassifier
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# Evaluate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy on test set: {accuracy:.2f}")

# Generate classification report
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Visualizations

# Boxplot: Distribution of Age by Survival
plt.figure(figsize=(10, 6))
sns.boxplot(x='Survived', y='Age', data=data)
plt.title('Age Distribution by Survival')
plt.show()

# Bar Chart: Count of Survivors vs Non-survivors
plt.figure(figsize=(10, 6))
sns.countplot(x='Survived', data=data)
plt.title('Count of Survivors vs Non-survivors')
plt.show()

# Pie Chart: Proportion of Survivors vs Non-survivors
plt.figure(figsize=(8, 8))
data['Survived'].value_counts().plot.pie(autopct='%1.1f%%', startangle=90, colors=['#ff9999','#66b3ff'])
plt.title('Proportion of Survivors vs Non-survivors')
plt.ylabel('')
plt.show()

# Feature Importances from the Random Forest model
importances = model.feature_importances_
indices = np.argsort(importances)[::-1]
feature_names = X.columns

# Bar Chart: Feature Importances
plt.figure(figsize=(10, 6))
plt.title('Feature Importances')
plt.bar(range(X.shape[1]), importances[indices], align='center')
plt.xticks(range(X.shape[1]), [feature_names[i] for i in indices], rotation=90)
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(x='Survived', y='Age', data=data)
plt.title('Age Distribution by Survival')
plt.xlabel('Survived')
plt.ylabel('Age')
plt.xticks([0, 1], ['No', 'Yes'])
plt.show()



